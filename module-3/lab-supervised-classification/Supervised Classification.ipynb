{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised classification\n",
    "\n",
    "In the data.csv there are letters (uppercases and lowercases) and numbers, 28x28 pixels in a row format.\n",
    "\n",
    "* First, you need to know which labels are which, meaning you need to visualize some data to realize which number labels represents a letter, or a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "data = pd.read_csv('C:/Users/Data Analyst/Documents/GitHub/datamex0120/module-3/lab-supervised-classification/data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116322, 785)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mat = data.values\n",
    "for i in range(0):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(mat[i,1:].reshape(28,28))\n",
    "    plt.show();\n",
    "    print(mat[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones train: X=(90000, 749), Y=(90000, 10)\n",
      "\n",
      "Dimensiones test: X=(26322, 749), Y=(26322, 10)\n"
     ]
    }
   ],
   "source": [
    "### General model test\n",
    "carac=mat[:,0]        # caractéres\n",
    "Y=np.zeros((mat.shape[0],10)) \n",
    "X=mat[:,1:]               # variables indep\n",
    "X=X[:,X.sum(axis=0)!=0]            # se quitan las columnas de 0 \n",
    "X_train, Y_train=X[0:90000,:], Y[0:90000,:]        # datos de entranamiento\n",
    "#X_train_sk=X_train.copy()                          # para sklearn\n",
    "\n",
    "X_test, Y_test=X[90000:,:], Y[90000:,:]            # datos de test\n",
    "#X_test_sk=X_test.copy()                            # para sklearn\n",
    "\n",
    "print ('Dimensiones train: X={}, Y={}'.format(X_train.shape, Y_train.shape))  \n",
    "print ('')\n",
    "print ('Dimensiones test: X={}, Y={}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac_train=carac[0:90000]       # carac entrenamiento\n",
    "carac_test=carac[90000:]         # carac test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, try to train a classifier model to predict the uppercases. Use every single model you know for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Data Analyst\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(C=0.01, penalty='l2', tol=0.0001, max_iter=70,\n",
    "                          solver='lbfgs', multi_class='multinomial').fit(X_train, carac_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_sk(datos):\n",
    "    for e in datos:\n",
    "        nombre, carac, Xs=e\n",
    "        etiq=carac.size\n",
    "        \n",
    "        y_pred_sk=logreg.predict(Xs)\n",
    "        \n",
    "        cuenta=0\n",
    "        for muestra in range(etiq):\n",
    "            if y_pred_sk[muestra]==carac[muestra]:         \n",
    "                cuenta+=1\n",
    "        \n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento  :\n",
      "65529 correctos de 90000 ==> 72.81% correcto\n",
      "\n",
      "Test  :\n",
      "18641 correctos de 26322 ==> 70.82% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen_sk([('Entranamiento  :', carac_train, X_train)])\n",
    "resumen_sk([('Test  :', carac_test, X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with lowercases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "minu = data[(data.e>=9) & (data.e<=34)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36567, 785)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = minu.values\n",
    "minu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones train: X=(29000, 683), Y=(29000, 10)\n",
      "\n",
      "Dimensiones test: X=(28918, 683), Y=(28918, 10)\n"
     ]
    }
   ],
   "source": [
    "carac=mat1[:,0]        # caractéres\n",
    "Y=np.zeros((mat1.shape[0],10)) \n",
    "X=mat1[:,1:]               # variables indep\n",
    "X=X[:,X.sum(axis=0)!=0]            # se quitan las columnas de 0 \n",
    "X_train, Y_train=X[0:29000,:], Y[0:29000,:]        # datos de entranamiento\n",
    "#X_train_sk=X_train.copy()                          # para sklearn\n",
    "\n",
    "X_test, Y_test=X[29000:,:], Y[29000:,:]            # datos de test\n",
    "#X_test_sk=X_test.copy()                            # para sklearn\n",
    "\n",
    "print ('Dimensiones train: X={}, Y={}'.format(X_train.shape, Y_train.shape))  \n",
    "print ('')\n",
    "print ('Dimensiones test: X={}, Y={}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac_train=carac[0:29000]       # carac entrenamiento\n",
    "carac_test=carac[29000:]         # carac test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Data Analyst\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression(C=0.01, penalty='l2', tol=0.0001, max_iter=70,\n",
    "                          solver='lbfgs', multi_class='multinomial').fit(X_train, carac_train) ### Logreg moel\n",
    "def resumen_sk(datos):\n",
    "    for e in datos:\n",
    "        nombre, carac, Xs=e\n",
    "        etiq=carac.size\n",
    "        \n",
    "        y_pred_sk=logreg.predict(Xs)\n",
    "        \n",
    "        cuenta=0\n",
    "        for muestra in range(etiq):\n",
    "            if y_pred_sk[muestra]==carac[muestra]:         \n",
    "                cuenta+=1\n",
    "        \n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento  :\n",
      "27505 correctos de 29000 ==> 94.84% correcto\n",
      "\n",
      "Test  :\n",
      "26894 correctos de 28918 ==> 93.0% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen_sk([('Entranamiento  :', carac_train, X_train)]) ### Train results\n",
    "resumen_sk([('Test  :', carac_test, X_test)])      ### Test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data[data.e<=9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57918, 785)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = num.values\n",
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones train: X=(46000, 683), Y=(46000, 10)\n",
      "\n",
      "Dimensiones test: X=(11918, 683), Y=(11918, 10)\n"
     ]
    }
   ],
   "source": [
    "carac=mat1[:,0]        # caractéres\n",
    "Y=np.zeros((mat1.shape[0],10)) \n",
    "X=mat1[:,1:]               # variables indep\n",
    "X=X[:,X.sum(axis=0)!=0]            # se quitan las columnas de 0 \n",
    "X_train, Y_train=X[0:46000,:], Y[0:46000,:]        # datos de entranamiento\n",
    "#X_train_sk=X_train.copy()                          # para sklearn\n",
    "\n",
    "X_test, Y_test=X[46000:,:], Y[46000:,:]            # datos de test\n",
    "#X_test_sk=X_test.copy()                            # para sklearn\n",
    "\n",
    "print ('Dimensiones train: X={}, Y={}'.format(X_train.shape, Y_train.shape))  \n",
    "print ('')\n",
    "print ('Dimensiones test: X={}, Y={}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac_train=carac[0:46000]       # carac entrenamiento\n",
    "carac_test=carac[46000:]         # carac test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Data Analyst\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression(C=0.01, penalty='l2', tol=0.0001, max_iter=70,\n",
    "                          solver='lbfgs', multi_class='multinomial').fit(X_train, carac_train) ### Logreg moel\n",
    "def resumen_sk(datos):\n",
    "    for e in datos:\n",
    "        nombre, carac, Xs=e\n",
    "        etiq=carac.size\n",
    "        \n",
    "        y_pred_sk=logreg.predict(Xs)\n",
    "        \n",
    "        cuenta=0\n",
    "        for muestra in range(etiq):\n",
    "            if y_pred_sk[muestra]==carac[muestra]:         \n",
    "                cuenta+=1\n",
    "        \n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento  :\n",
      "43416 correctos de 46000 ==> 94.38% correcto\n",
      "\n",
      "Test  :\n",
      "11131 correctos de 11918 ==> 93.4% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen_sk([('Entranamiento  :', carac_train, X_train)]) ### Train results\n",
    "resumen_sk([('Test  :', carac_test, X_test)])      ### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conclusion: for numerical characters, the model fits better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
